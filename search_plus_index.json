[{"url":"./","title":"实验框架","level":"1.1","keywords":[],"body":"实验框架整体设计说明 层级划分 实验框架设计上的整体架构按照各次实验内容进行了层次划分，从底层的操作系统级别的页式文件管理到顶层的SQL命令行交互，主要可以划分为如下的层级结构。 上述图片中模块后编号表示对应的实验编号。 此处按照实验设计的顺序简单介绍各个模块的主要功能： 缓存和磁盘：底层缓存和磁盘管理，支持类 UNIX 操作系统（Linux + Mac），不支持 Windows 操作系统。 日志：仅负责存储日志信息。 记录管理：负责数据库系统中关系内记录的管理，实现了对于表(Table)，记录(Record)，以及字段(Field)等数据库系统基本组成部分的抽象，同时负责处理这些基本组成部分的到实际物理页面的序列化和反序列化。 事务管理：负责日志的解析以及在基于日志的自动恢复等操作，需要负责处理事务重做和事务回滚。 执行器：基于火山模型设计的简单执行器，基于上层给出的执行计划树完成查询的实际执行过程。 优化器：接收解析器的语法分析树，经过逻辑优化和物理优化过程转化为执行计划树。 并发控制：负责多个事务并发进行情况下的执行过程控制，管理锁和记录的多版本信息。 解析器：SQL语法解析，将原始SQL转化为语法分析树。 前端命令行：负责用户交互，实时接收SQL语句输入并给出查询结果的输出 SQL整体运行流程 如图所示，系统整体的工作流程主要可以概括为如下几个子过程： SQL解析：将原始SQL查询语句转化为抽象语法树 优化器：对于抽象语法树进行逻辑优化和物理优化过程，生成执行计划树 执行器：按照火山模型完成执行计划树，通过不同算子实现对于页面数据的访问和修改 功能模块划分 实验框架的源代码按照功能模块进行组织，此处按照各次实验中涉及的各个功能模块进行简单介绍： LAB 1 记录管理 record 模块 实现了记录(Record)和字段(Field)类型，实现了包括反序列化(Load)、序列化(Store)等基本函数。 table 模块 实现了表(Table)类型，表结构包含表的元信息(TableMeta)以及页面文件组成的实际存储数据。通过PageHandle类可以实现物理页面的无格式数据到格式化记录的转化和操作。同时，可以通过配置隐藏列的方式向数据表中存储声明字段外的额外字段、例如后续实验中需要使用的记录标识(RID)、版本号(VERSION)、锁状态(WR_LOCK)等。 LAB 2 事务与日志 log 模块 实现了日志(Log)的序列化和解析，采用物理日志的方式记录数据变化。管理事务的REDO和UNDO过程。同时需要管理日志数据的组织和持久化过程，对于LAB 1实验没有影响。 storage 模块 底层缓存、磁盘的管理，由于缓存数据保存在内存中，需要结合日志模块以及磁盘保证写入数据的持久性。 LAB 3 并发控制 整体性的功能添加，本次实验中没有设计单独的独立功能模块。 LAB 4 执行器 exec 模块 执行器模块，包装了简单的执行器模型。对于每个事务建立新的执行器并记录基本的元信息，管理算子实际执行过程。 oper 模块 实现了抽象类算子结点(OperNode)，算子结点组织成树结构可以构成执行计划树，通过实现不同算子结点的Next函数，可以实现以向量化模型为基础的执行引擎。 LAB 5 优化器 optim 模块 实现了优化器(Optimizer)，对于上层visitor解析的抽象语法树进行逻辑优化和物理优化两个过程，形成高效的执行计划交由底层执行引擎进行处理。 其余模块 utils 模块 一些常用的数据结构，此处给出了并查集(UFSet)以及位图(Bitmap)。 result 模块 用于查询结果的输出，包含记录头和记录内容。 system 模块 数据库管理模块，主要实现了元信息的管理。 parser 模块 解析器模块，将SQL语句转化为抽象语法树。 Extra cli.cpp为主程序入口。defines.h是通用头文件，可以将常量值和常用的类型声明置于该文件内。 last update at: 2023/3/6 17:02:29 "},{"url":"test.html","title":"测试说明","level":"1.2","keywords":[],"body":"测试说明 环境配置 本实验依赖 cmake, make, g++ 构建工具，其中 g++ 需要支持 C++17 标准，编译解析器需要 flex 和 bison 工具，需先在本地环境安装这些依赖。 由于实验框架底层文件操作调用了 Unix 相关接口，故不支持 Windows 环境，Windows 用户建议使用 WSL，或使用 Virtualbox 或 VMWare 开一个 Ubuntu 虚拟机，然后参考下面的 Ubuntu 环境配置。 Ubuntu 环境配置 建议使用 Ubuntu 22.04 及更高版本，使用 apt 安装依赖： sudo apt install cmake make flex bison g++ macOS 环境配置 使用 homebrew 安装依赖： brew install cmake flex bison 测试是否配置好了环境 g++ -v flex --version bison --version cmake --version 运行实验框架 配好环境后，按照以下步骤进行操作： 拉取实验仓库并重命名 使用 git clone 和 mv 命令（将 20xxxxxxxx 替换为你的学号）： git clone git@git.tsinghua.edu.cn:dbtrain/2023/dbtrain-20xxxxxxx.git mv dbtrain-20xxxxxxx dbtrain-lab 仓库重命名操作是必须的，否则测试脚本无法正常工作。 拉取测试仓库 在同一文件夹下，使用 git clone 命令拉取测试仓库。 git clone git@git.tsinghua.edu.cn:dbtrain/dbtrain-lab-test.git 测试仓库应与实验仓库在同一父文件夹下，目录结构应为： <diretory> ├── dbtrain-lab │ ├── src │ ├── CMakeLists.txt │ ├── .gitlab-ci.yml │ ├── ... ├── dbtrain-lab-test │ ├── lab1 │ ├── check.py │ ├── ... └── ... 新一次实验发布时，测试仓库可能会更新，开始新实验前请先通过git pull命令更新测试仓库。 编译实验框架 进入 dbtrain-lab 目录，运行如下命令进行编译： cd dbtrain-lab mkdir build && cd build cmake .. make -j4 或使用写好的编译脚本文件： ./build.sh 由于实验框架中部分函数需要同学们自己实现，所以编译过程中出现 non-void function does not return a value [-Wreturn-type] 或 no return statement in function returning non-void [-Wreturn-type] 的 warning 是正常的。 如果环境配置没有问题，应成功编译出可执行程序 cli ： ... [ 94%] Linking CXX static library ../lib/libthdb.a [ 94%] Built target thdb Scanning dependencies of target cli [ 97%] Building CXX object src/CMakeFiles/cli.dir/cli.cpp.o [100%] Linking CXX executable ../bin/cli [100%] Built target cli 运行 ./bin/cli 即可进入数据库交互界面： ./bin/cli dbtrain> show databases; +----------+ | Database | +----------+ dbtrain> create database test; +---------+ | SUCCESS | +---------+ dbtrain> show databases; +----------+ | Database | +----------+ | test | +----------+ (1 rows) dbtrain> 通过 ctrl+c 或 ctrl+d 即可退出数据库交互界面。 数据库交互程序支持 -s 参数，该参数用于控制结果打印格式，加上该参数后将只打印必要字段，不打印表格框： ./bin/cli -s dbtrain> use test; SUCCESS dbtrain> create table t(id int, name char(4), score float); SUCCESS dbtrain> desc t; Name | Type | Length id | INT | 4 name | STRING | 4 score | FLOAT | 8 该参数主要用于测试脚本进行结果比对，你在本地与数据库交互时无需使用该参数。 测试脚本使用方法 测试仓库目录结构如下： dbtrain-lab-test ├── README.md ├── check.py ├── lab1 │ ├── result │ │ ├── 00_setup.result │ │ ├── 10_basic.result │ │ ├── 20_error.result │ │ ├── 30_long_text.result │ │ └── 40_many_rows.result │ └── test │ ├── 00_setup.sql │ ├── 10_basic.sql │ ├── 20_error.sql │ ├── 30_long_text.sql │ └── 40_many_rows.sql └── test.sh test.sh是为 CI 准备的脚本，本地测试不会用到它。 check.py 为测试脚本，在第 n 次实验中，该脚本会通过 ../dbtrain-lab/build/bin/cli -s 命令运行数据库，枚举 lab{1..n}/test 目录下的所有文件，将这些文件按照序号从小到大的顺序依次输入数据库。同时脚本会在 labx 文件夹下建立 tmp 文件夹，将数据库的标准输出重定向到 tmp 文件夹下的文件中，最后将 tmp 文件夹的文件与 result 文件夹的文件内容进行对比，文件内容一致即通过测试。 由于标准错误 stderr 不会被重定向到文件中，因此你可以在实验代码中使用 cerr 输出调试信息，cerr 输出的信息不会影响测试结果。 你可以通过 -l 或 --lab 参数控制脚本进行前几次 lab 的测试，如 python3 check.py -l 3 则会运行 lab1, lab2 和 lab3 的测试。 脚本默认会运行 test 目录下相应 lab 的所有文件，你可以通过 -u 或 --until 参数控制最后一次 lab 中脚本运行的文件，如 python3 check.py -l 2 -u 10 将只会运行 lab 2 的 00 和 10 两个测试文件（以及 lab 1 的所有测试文件）。 result 文件格式说明 result 文件的每个结果对应 sql 文件中一条 SQL 的期望输出，两个结果之间用一个空行隔开，一个典型的结果格式如下： -- 10.show tables; Tables t_basic t_basic_2 第一行表示当前运行的是第几条 SQL 及对应的 SQL 语句，仅用于增加文件可读性，测试脚本比对结果时会去掉该行。 接下来的几行表示期望输出结果，SQL 对输出结果顺序没有要求，脚本会先将结果排序后再进行比对，因此如果你的数据库输出如下： Tables t_basic_2 t_basic 也可以通过该条测试。 测试脚本输出 测试通过时，脚本会输出： Test 00_setup PASSED Test 10_basic PASSED Test 20_error PASSED Test 30_long_text PASSED Test 40_many_rows PASSED 5 / 5 cases PASSED 测试失败分为如下几种情况： 1.结果数目错误： Incorrect number of results Expected: 26 Got: 23 Test 00_setup FAILED 测试 00_setup 中共 25 条 SQL，期望输出 26 个结果（包括退出数据库时输出的 Bye），但实际只输出了 23 个结果，可查看是否有某些 SQL 运行失败导致没有输出结果。 2.结果行数错误： SQL 20 Incorrect length Expected: 3 Got: 1 Test 30_long_text FAILED 测试 30_long_text 的第 20 条 SQL 期望输出 3 行，实际输出 1 行。 3.结果错误： SQL 14 Incorrect result Expected: age | INT | 4 Got: age | INT | 12884901892 Test 00_setup FAILED 测试 00_setup 的第 14 条 SQL 输出结果与期望输出不一致，可在 result 文件中查看第 14 条 SQL 及对应输出。 4.异常退出： Traceback (most recent call last): File \"check.py\", line 105, in main if test_case.check(): File \"check.py\", line 46, in check tmp_results = tmp_result_file.read().splitlines() File \"/usr/lib/python3.8/codecs.py\", line 322, in decode (result, consumed) = self._buffer_decode(data, self.errors, final) UnicodeDecodeError: 'utf-8' codec can't decode byte 0x96 in position 347: invalid start byte Test 40_many_rows FAILED 脚本运行错误，具体原因需根据报错信息推测，本示例中是由于输出文本中包含异常字符导致运行错误。 "},{"url":"intro.html","title":"实验说明","level":"1.3","keywords":[],"body":"实验说明 代码位置 对于基础功能，仅需要正确补充填空区域的代码，实现对应的功能即可。 各次实验的填空区域均进行了注释，以LAB 1为例，仅需要在如下区间内填充代码即可。 // LAB 1 BEGIN // LAB 1 END 各位同学仅需要搜索对应的注释\"// LAB N BEGIN\"即可快速定位补充代码的区域。 更新说明 实验框架可能会有更新，此时需要将实验框架更新部分添加到当前的实验框架上。为了新增一个远程仓库，在你的 dbtrain-lab 仓库目录下执行： git remote add upstream git@git.tsinghua.edu.cn:dbtrain/dbtrain-lab-template.git 之后每次需要拉取新的分支时，执行 git fetch upstream 然后再将更新的分支并入你的代码，例如将 upstream 的 master 分支以 merge 方式并入当前分支，执行 git merge upstream/master merge 后可能产生冲突（如果你和上游仓库对同样的地方进行了不同的修改），这种情况请手动解决所有冲突并执行 git 的 add 和 commit 指令完成合并。 提交说明 评测通过 CI 进行，每当你在 master 分支上 push 更新时，评测机会自动将仓库的 src 文件夹进行编译，然后运行测试脚本进行测试。 不要私自修改 .gitlab-ci.yml 文件。 评测机环境为 Ubuntu 22.04，各工具版本如下： cmake 3.22.1 make 4.3 g++ 11.3.0 flex 2.6.4 bison 3.8.2 第 N 次实验截止后发布第 N + 1 次实验，防止出现提交错误。 第 N 次实验截止后发布一个 10 天的作业补交窗口。 作业仅需要提交对应版本的 commit id 以及实验报告，commit id 直接使用提交窗口的输入框提交，报告以 pdf 形式通过附件提交。 补交说明 CI 评测默认情况下只会进行当前阶段实验的测试，如在 lab 3 实验阶段会对 lab 1 至 lab 3 的相关测试进行评测，因此，若在 lab 2 补交阶段（同时也是 lab 3 实验阶段）才完成 lab 2 的实验，则会导致评测结果失败。 对于在 lab 3 实验阶段补交 lab 2 实验的同学，如想要只进行 lab 1 和 lab 2 的评测，可在实验仓库根目录下新建 LAB.txt 文件，文件内容为 2，表示想要进行 lab 2 阶段的测试，评测机会读取 LAB.txt 文件内容进行 lab 1 和 lab 2 相关测试。后续实验补交流程同理。 高级功能 高级功能不要求严格按照各次实验文档给出的推荐选项，只需要选择老师课程讲解过程中与实验相关的知识即可。 高级功能的添加要尽可能设计对应的测试用例，可以使用 SQL 测例，也可以使用 google-test 等工具进行单元测试。 高级功能的总评为 3 分，只需要给出一个合理的设计也能获得部分分数，但是希望取得高分则必须实现一些有挑战性的功能。 评分说明 每次实验 20 分，五次实验共 100 分。 对于每次实验： 15 分是自动化测试的结果，通过所有测试即可得到满分，可在 gitlab 的 CI 中查看测试结果。 2 分是实验报告分，具体见报告说明。 3 分是高级功能分，具体见每次实验的高级功能说明。 报告说明 内容要求 报告需要至少包括如下内容： 基本功能的实现难点。 实现每个功能大致用了多少时间，实验总耗时多少（该条仅用于课程调查，不影响评分）。 （可选）高级功能的设计与实现方式，以及代码对应的分支和commit id（如果有的话）。 报告格式 要求为 pdf 格式。 没有具体内容模板，但是建议从报告结构上突出重点内容，例如采用标题突出段落重点。 不要直接将大段代码复制到报告中。 报告不要过长，过于冗长的报告可能会影响你的分数。 可以使用标准的示意图来展示自己的设计，不要使用过于抽象的手绘示意图。 BUG Report 对于实验框架的BUG可以在网络学堂的课程讨论区进行发布，方便其他同学查看。此处给出BUG Report的标准格式。 【重要BUG】\\【一般BUG】 位置: xxx.cpp(文件名) 117(debug分支中对应起始行号) 说明: ......(简要的说明文字) （如果有补丁文件，直接利用git diff创建补丁，置于附件中即可） git diff补丁文件制作方法教程： ## 建议每次修复BUG重新建立分支 git checkout -b debug-patch(任意分支名) ## 修复BUG git add . git commit -m \"Fix a bug in ...\" git diff debug > xxx.patch(任意patch名) ## 提交xxx.patch文件到讨论区 其他说明 1.时间规范 各位同学需要严格按照各个实验的截止时间完成各次实验任务，对于没有按时完成实验的同学会在实验得分上收到一定影响。 迟交实验具体的惩罚措施如下： 迟交成绩 = MAX(0, 实际成绩 × (1 - 0.1 × 迟交天数)) 2.诚信规范 各位同学一定要独立完成各次实验，本课程鼓励同学们思想上的交流，但不建议同学们直接进行代码交换，也不要抄袭往届学长学姐的代码。如果发现严重的代码雷同，可能会面临助教谈话甚至于实验记为0分的风险。 3.保密规范 各位同学一定不要将本实验放到公共仓库上。 "},{"url":"lab1.html","title":"lab 1: 记录管理","level":"2.1","keywords":[],"body":"LAB 1 记录管理实验文档 实验概述 本次实验主要关注于数据库底层记录管理模块的功能，理解无格式的原始字节数据到与格式化的记录之间的转化过程。重点关注于关系型数据库系统在页式文件管理系统中表的数据组织，如何在定长页面中管理记录的存储和加载。 实验任务 本次实验主要有两个任务： 阅读代码，对于记录管理模块有一个结构性的理解 设计底层记录页面组织，完成记录管理的各项基本功能 相关模块 record 模块：需要理解 Record 和 Field 的基本函数，同时实现 Record 的存储和加载函数。 table 模块：需要理解 Table 的基本函数，在实验中不要求处理数据表元信息 (TableMeta)。重点关注于通过 PageHandle 在定长的页面中组织记录数据。 基础功能实现顺序 table/table_meta.cpp: TableMeta 的序列化和反序列化。 record/record_factory.cpp: 字段 Field 和记录 Record 的序列化和反序列化 table/page_handle.cpp: 页面内的记录插入、更新、删除 table/table.cpp: 上层记录插入、更新、删除的接口函数 可选高级功能 不要求将高级功能集成到主分支中，建议单开分支完成实验。但是建议同学们设计验证自己实验结果的测例并给出测试的可视化结果展示。 变长记录存储：实现 varchar 类型的变长存储，需给出实现方式的示意图，以及使用前后存储空间变化。 数据加密或数据压缩：使用加密或压缩相关库对表数据进行加密和压缩，同时支持数据的查询和更新，需给出相关性能参数（如压缩加密的时间，对查询性能的影响）以及实际HEX编码变化。 删除记录空间回收：自动回收已经删除的记录条目所占用的空间，设计回收策略，如什么时候进行回收，如何回收，需要给出执行效率和存储空间变化 同时也鼓励同学们结合相关课程内容提出自己的创新设计。 考虑到本次实验高级功能实现难度较大，只需完整实现一个高级功能即可得到满分，如果没有实现高级功能，可以在报告中写出高级功能的设计方式，也可得到部分分数。 特别注意第二项数据加密最好采用记录或字段级别的相关加密技术，或者包含完整密钥管理的成熟页面级别加密技术。简单在页面IO过程中使用同密钥加密的安全性不足，无法获取全部分数。数据压缩则重点需要考虑到数据更新过程中的优化。简单在IO过程中直接调用压缩和解压函数的更新效率同样无法获取全部分数。 一条 SQL 语句的运行流程 为理解实验框架工作流程，我们以 show databases 语句为例，来分析 SQL 是如何一步步转化为我们期望的结果的。 cli 程序的主函数位于 cli.cpp 文件，该文件的核心代码为： ast:: Visitor *visitor = new ast:: Visitor(); Result result = std::any_cast<Result>(ast::parse_tree->accept(visitor)); printer->Print(&result); delete visitor; 对于输入的 SQL 文本，首先通过 yyparse 函数对 SQL 进行解析，语法文件位于 parser/sql.y，解析后将 SQL 转化为语法树节点，语法树节点的定义位于 parser/ast.h 文件。 随后通过 ast::parsetree->accept 方法对语法树进行遍历，解析器采用 visitor 模式，遍历时程序会进入 SQL 语句对应的 visit 函数中，对于 show databases 这条 SQL 语句，遍历后会进入 parser/visitor.cpp 的 Visitor::visit(ShowDatabases *) 函数： std::any Visitor::visit(ShowDatabases *) { return SystemManager::GetInstance().ShowDatabases(); } 该函数直接调用 SystemManager 对象的 ShowDatabases 函数，位于 system/system_manager.cpp 文件： Result SystemManager:: ShowDatabases() { RecordList records; for (const auto &db_name : db_names_) { Record *record = new Record(); record->PushBack(new StrField(db_name.c_str(), db_name.size())); records.push_back(record); } return Result(std::vector<std::string>{\"Database\"}, records); } SystemManager 为数据库的系统管理模块，主要负责数据库的创建、删除、查找、切换、关闭，表的创建和删除功能。该类采用单例模式实现，只需调用 SystemManager::GetInstance() 即可获得 SystemManager 对象。 由于 SystemManager 在初始化时已经在 db_names_ 中记录了当前所有数据库的名称，我们只需将 db_names_ 的内容包装为 Result 对象即可。 查看 result/result.h 中 Result 类的定义： class Result { ... private: std::vector<std::string> header_; RecordList records_; }; 发现该类的数据成员由 header_ 和 records_ 组成，分别表示输出结果的表头和输出结果的内容，对于 show databases 命令，我们简单地将 header_ 设置为 Databases，然后只需将 db_names_ 包装为 RecordList 对象，一个结果对象的组成部分如下： 在 record/record.h 文件中找到 RecordList 以及 Record 的定义： typedef vector<Record*> RecordList; class Record { ... private: vector<Field*> field_list_; RecordList 为由多个 Record 指针组成的数组，Record 类由 Field 指针数组组成。 再从 record/field.h 文件中找到 Field 类的定义，同时发现 Field 类被 IntField, FloatField 和 StrField 类继承，对于 show databases 的结果，我们需要将每个数据库的名称包装为 StrField 的对象，然后依次构建 Record, RecordList，最终构建出 Result 对象，这就是 SystemManager 的 ShowDatabases 函数所做的事情。 返回 Result 结果后，cli 函数通过 printer->Print(&result) 将结果打印出来，一条 SQL 的运行就结束了。 如需了解 Insert, Delete, Update, Select 等语句的运行过程，可查看 parser/visitor.cpp 中对应的 visit 函数，这些语句运行过程中可能需要 Preprocessor 类为 SQL 中的列添加对应的表，随后通过 Optimizer 构造相应的算子节点并生成查询计划，最后通过执行器的 RunNext 函数执行查询，具体代码位于 optim 和 oper 两个文件夹下，实验 1 需要重点关注 oper/scan_node.cpp 中的 TableScan 节点的实现。 建议同学们开始实验前首先阅读代码，充分了解不同 SQL 的运行过程，然后再填充缺失代码，了解实验框架也会为之后的实验带来帮助。 每创建一个数据库，会生成一个文件夹，文件夹里会存在 LOGDATA, LOGIDX 和 MASTER 等文件，这些是 lab2 相关的日志文件，你在 lab1 无需关注；每创建一张表，会生成两个文件，后缀名为 .meta 和 .data，分别存储表的结构元信息（表中有多少个列，每列的数据类型，每列的长度，以及一些关于表的页面的相关信息）和表的数据。 在实验 1 中，你需要首先实现 table_meta 的 Load 和 Store 函数，这两个函数实现了表的元信息加载存储，Load 函数将页面中的无格式字节数据反序列化为内存中的数据信息，Store 函数将内存中记录的信息通过序列化存储到页面中，并进一步由 BufferManager 存储到磁盘，从而实现表的元信息的持久化存储，正确实现此功能后，你应该可以成功通过 00_setup 的第 14 条 SQL（前 13 条 SQL 不需要对实验框架做任何修改即可通过）。 随后你需要实现 record/record_factory.cpp, table/page_handle.cpp, table/table.cpp 中的相关函数，建议实现之前先通过阅读代码了解 Insert, Delete, Update, Select 语句的运行过程，思考如何设计存储页面，然后根据注释填充代码。 截止时间 2023 年 3 月 26 日（第五周周日）晚 23:59 分。 "},{"url":"lab2.html","title":"lab 2: 日志管理","level":"2.2","keywords":[],"body":"LAB 2 日志管理实验文档 实验概述 本次实验主要关注于数据库系统的日志记录及故障恢复功能，希望同学们通过本次实验能够更好地理解数据库日志的记录方式以及日志对于故障恢复过程的作用。重点关注于简化的ARIES算法的实现，以及日志记录和管理的方式。 实验任务 本次实验主要有3个任务： 阅读新增的代码，理解日志记录的过程。 补全未完成的日志设计：Update日志镜像的部分函数以及Checkpoint日志的部分函数。 完成简化的ARIES算法：本次实验下仅要求支持单线程场景。 实验开始前，请按照文档中更新说明中的步骤合并新增代码。 相关模块 tx 模块：事务管理模块，负责事务ID的管理，维护线程ID与事务的XID的对应关系，本次实验中不需要重点关注。 log 模块：日志管理模块，负责处理日志记录以及故障恢复功能。是本次实验需要重点关注的部分，尤其是LogManager模块中包含了本次实验的绝大部分内容。 table 模块：在LAB 1代码基础上添加记录WAL日志的过程。 基础功能实现顺序 table/table.cpp: 在LAB 1代码基础上添加记录WAL日志的过程。 log/log_manager.cpp: 首先完成三种基本操作(INSERT/DELETE/UPDATE)的日志记录过程。 log/log_image.cpp: Update日志镜像的设计，实现物理逻辑日志的序列化和反序列化。 log/update_log.cpp: 基于日志镜像完成Redo和Undo的具体操作。 log/checkpoint_log.cpp: Checkpoint日志的设计，与其他日志不同之处在于，Checkpoint日志在Load过程中需要将数据更新到LogManager的成员变量，完成加载过程。 log/log_manager.cpp: 完成故障恢复算法，实现 Redo 和 Undo 函数。 测试说明 本次实验新增了 begin, abort, commit, checkpoint, crash, flush 相关语法： begin, abort, commit 分别对应事务的开始、回滚和提交。 checkpoint 使系统写入一个检查点。 crash 模拟系统故障崩溃，调用 BufferManager 的 Clear 函数清空缓冲区所有内容。 flush 调用 BufferManager 的 FlushAll 函数将缓冲区内容同步到磁盘。 不要修改 visitor 中 flush 和 crash 相关函数的代码 本次实验中，基本测试为简单的测试样例，没有包含复杂的故障恢复场景，仅考虑完成基本功能的同学不需要考虑如下场景的故障恢复： 修改 TableMeta 后出现故障的场景。 修改 PageHeader.next_free 后出现故障的场景。 插入记录导致新的页面分配后，系统出现故障，导致 redo 过程中页面缺失的场景。 本次实验的基本测试具有一定局限性，但是希望同学们能发掘更多的场景，探索在这些场景下恢复算法的应对策略。这也是本次实验高级功能的一个选择。 可选高级功能 不要求将高级功能集成到主分支中，建议单开分支完成实验。但是建议同学们设计验证自己实验结果的测例并给出测试的可视化结果展示。 复杂的日志恢复场景(1分)：实现能够适应复杂场景的日志恢复算法，解决基本测试的三点局限性，需要自行添加额外测例（需要添加对于Meta信息的日志，报告中需要写出相关设计）。 非阻塞的Checkpoint日志记录(1分)：需要将Checkpoint日志拆分为 begin_checkpoint 和 end_checkpoint，单开线程进行 checkpoint 写入操作，写入checkpoint 时不阻塞 SQL 的正常运行，需要自行添加额外测例（日志写回进程可以人工添加一定延时，报告中需要展示出检查点begin到end存在增删改查日志）。 Undo过程中系统出现异常的恢复(1分)：添加CLR日志，让系统支持在undo过程中的异常恢复，需要自行添加额外测例（为了模拟undo过程中的中断，可以添加undo过程中的abort指令）。 日志缓存(1分)：添加日志缓存机制，同时修改现有的数据缓存替换算法，利用FlushedLSN限制可写回的数据页面，需要自行添加额外测例（建议设置合理的日志缓存容量和足量的SQL测例，保证日志缓存能限制部分页面的写回）。 同时也鼓励同学们结合相关课程内容提出自己的创新设计。实验框架对于本次实验的几个高级功能有相对良好的支持，各个高级功能都比较容易完整实现，所以同学们可以选择同时支持多个高级功能来实现更为完整的基于日志的故障恢复算法。 高级功能满分3分。 截止时间 2023 年 4 月 9 日（第七周周日）晚 23:59 分。 "},{"url":"lab3.html","title":"lab 3: 并发控制","level":"2.3","keywords":[],"body":"LAB 3 并发控制 实验概述 本次实验主要关注于数据库系统的并发控制，重点关注于基于MVCC技术的多线程事务处理。通过实现MVCC机制实现多线程情况下的并发事务处理，让同学们对于数据库系统中并发控制机制有进一步的理解。 实验任务 本次实验主要有3个任务： 修改CheckPointLog接口，增加当前事务编号的存储和恢复过程。 设置和获取记录隐藏列，添加对应的接口。 修改PageHandle，实现多线程情境下的记录页面控制。 修改Table接口，实现适应MVCC场景的增删改查。 实验开始前，请按照文档中更新说明中的步骤合并新增代码。 相关模块 tx/lock_manager: 锁管理服务，可以定义并操作共享锁。可以用于保护数据页面的读写并发。 tx/signal_manager: 信号管理服务，可以定义信号并等待信号。可以利用信号机制控制不同线程之间的执行顺序。 基础功能实现顺序 log/checkpoint_log: 增加当前事务编号的存储和恢复过程。 record/record_factory: 添加操作隐藏列的接口。 table/page_handle.cpp: 实现多线程场景下的记录页面的插入、删除和查找。 table/table.cpp: 修改多线程场景下的表的插入、删除和更新。 测试说明 本次实验主要考察并发过程中事务之间的隔离性问题，通过多版本并发控制实现快照隔离，测试中增加了 declare, enddecl, signal, wait, run 等指令。 declare 和 enddecl 用于声明一个事务块，定义一个事务所包含的 SQL 语句，但并不执行这些 SQL。 run 用于并发执行事务，如 run t1, t2, t3 表示并发执行 t1, t2, t3 三个事务。 wait 和 signal 用于控制事务之间的并发，wait t1_2 表示等待信号 t1_2，其他事务可以通过 signal t1_2 发出信号 t1_2，从而使等待信号 t1_2 的事务继续进行。 可选高级功能 不要求将高级功能集成到主分支中，建议单开分支完成实验。但是建议同学们设计验证自己实验结果的测例并给出测试的可视化结果展示。 MVCC 的垃圾回收(1分)。由于 MVCC 机制中删除操作并没有真正删除对应的记录，仅仅标记了相应记录对应的版本号，使系统存在一些不需要的垃圾数据。设计算法回收垃圾数据所占用的空间，说明算法设计的要点，如垃圾回收的时机，垃圾数据的判定方法等，并需设计测例证明垃圾回收前后存储空间的变化情况。 写写冲突的处理(2分:1分基础+1分死锁)。当前测例仅包含读写冲突，在 MVCC 并发控制机制下不会发生阻塞，设计算法正确处理并发条件下的写写冲突问题，需详细给出写写冲突的处理方法,尤其是涉及死锁问题的处理(死锁占1分，死锁检测或死锁避免方法均可),并设计测例证明算法正确性(无死锁测例+有死锁测例，建议画一下测例的并发流程图)。 高级功能满分3分。 框架错误说明 经同学指出，目前的实验框架存在如下错误： table.cpp 的 InsertRecord 函数中，首先读取了表的元信息，确定插入记录的 page_id 和 slot_id 等，插入后对表的元信息进行了更新，这些操作没有对元信息进行加锁，可能导致多个线程同时插入数据时产生错误。 UpdateRecord 函数在实验3中拆分成了 DeleteRecord + InsertRecord 两个部分，而 UpdateNode 是通过 ScanNode 的 Next 方法以页为粒度进行 LoadRecords 操作。假设 page 0 已满，且有一个 record 需要 update，由于 delete 不会真正将 page 0 的 record 删除，新的 insert 会被插入 page 1，此时 UpdateNode 会调用 Next 函数对 page 1 进行 LoadRecords 操作，新插入的记录会被重新 delete + insert 一次。在本次实验的测例中，该错误不会影响正确性，但如果一页只能存放一个 record，该错误会造成死循环。 以上错误不影响基础功能的实现与测试，也不会对后续实验产生影响，由于修复错误需要对框架进行较大幅度的改动，可能影响已经完成实验的同学的评测结果，本学期暂不对以上错误进行修复，感谢同学对框架错误的反馈。 截止时间 2023 年 4 月 23 日（第九周周日）晚 23:59 分。 "},{"url":"lab4.html","title":"lab 4: 执行器","level":"2.4","keywords":[],"body":"LAB 4 执行器实验文档 实验概述 本次实验主要关注于 SQL 执行流程，重点为 join 算子的实现。 实验任务 完成 AndConditionNode 和 OrConditionNode 的构建过程。 实现 JoinNode 的构建和执行过程。 相关模块 optim 模块：负责新建执行算子节点。 join_node 模块：定义了 join 算子的执行过程。 基础功能实现顺序 optim/optim.cpp: 实现 AndConditionNode 和 OrConditionNode 的 visit 函数。 optim/optim.cpp: 实现 JoinConditionNode 的 visit 函数。 optim/optim.cpp: 在 Select 的 visit 函数中添加连接算子的部分。 oper/join_node.cpp: 实现 Next 函数，进行连接运算。 可选高级功能 实现多种 join 算法(1分)：至少实现三种不同的连接算法，如 Nested Loop Join, Sort Merge Join, Hash Join，设计测例比较不同算法的效率（仅要求2表Join的比较，要求涉及测例中join双方涉及条目数量有数量级差异的多组测试）。 基于外存的 join 算子(1分)：至少实现一种外存算法，如外存 Hash、外存 Sort Merge 等。注意外存算法同样需要进行页式管理，设计的测例要求中间结果超过一个页面存储容量，同时要在报告中写明中间结果占用页面的回收机制。 实现聚合算子(1分)：实现 SUM, AVG, MIN, MAX, COUNT 算子以及配套的GROUP BY算子，并设计测例验证正确性。其中测例中GROUP BY算子要求至少达到3个分组，其中至少有1个分组涉及的数据条目超过2条。 高级功能满分 3 分。 实现要点 对于多个 AND 或 OR 连接的条件，解析器会将条件解析为左深树，即所有 AND 结点的右孩子均为比较条件或连接条件，不会是其他 AND OR 条件。 所有 visit 函数必须具有返回值，即必须以 return 语句结尾。如不需要返回值可返回 nullptr，没有返回值可能出现 Segmentation fault。 实现 visit 函数时可参考 optim 中其他节点 visit 函数的代码。 使用并查集维护表的连接信息，并查集实现代码位于 utils/uf_set.h 文件。 截止时间 2023 年 5 月 7 日（第十一周周日）晚 23:59 分。 "},{"url":"lab5.html","title":"lab 5: 优化器","level":"2.5","keywords":[],"body":"LAB 5 优化器 实验概述 本次实验主要关注于数据库系统的查询计划优化过程，重点关注于逻辑优化中的连接顺序选择。通过实现简单的基数估计算法和连接顺序选择算法，让同学们对于数据库系统中逻辑优化的过程有更进一步的理解。 实验任务 本次实验主要有3个任务： 实现直方图的数据结构。 补全Filter算子的基数估计过程。 完成Optimizer中连接顺序优化过程。 实验开始前，请按照文档中更新说明中的步骤合并新增代码。 相关模块 utils/graph: 实现了基于邻接表的无向图 optim/stats_manager: 用于管理统计信息，包括直方图的存储 基础功能实现顺序 utils/histogram.cpp: 补全直方图的构建和估计函数。 optim/stats_manager.cpp: 补全读取表的数据并构建直方图的过程。 oper/basic_node.cpp: 补全Filter算子的基数估计过程。 optim/optim.cpp: 完成Optimizer中连接顺序优化过程。 连接顺序优化示例 下面，结合一个简单的示例来解释连接顺序的优化过程。此处以30测例中第一条查询语句为例： explain select t2.id from t1, t2, t3, t4 where t3.score < 80.0 and t4.id = t3.id and t3.id = t2.id and t2.id = t1.id; 经过基数估计过程，可以得出各个表对应的执行树算子基数分别约为： 表名 基数 t1 10 t2 50 t3 约80 t4 100 此时，我们以表作为结点，连接关系作为边，可以生成一张无向的连接图。 考虑到join基数估计较为困难，基础功能只需使用一种非常简单的启发式算法，从最小基数结点出发依次添加相邻最小基数结点的贪心过程。 实际执行过程如下： 首先，选择最小基数结点t1，此时邻接结点集合为{t2}，已连接结点集合为{t1} 当邻接结点集合不为空时，从邻接结点集合取出最小基数结点添加到已连接结点集合，本步骤即为取出t2，此时邻接结点集合为{}，已连接结点集合为{t1,t2}。 将新添加结点的所有不在已连接集合的邻接结点加入到邻接结点集合，本步骤将添加t3，此时邻接结点集合为{t3}。 重复2,3直至邻接结点集合为空。 注意，每次步骤2取出新结点时，新的结点和已经完成连接的部分存在且仅存在1条连接关系（不考虑多列连接），每次执行步骤2时按顺序记录这条连接关系，取出{t2}时连接顺序为{t1.t2}，取出t3时连接顺序为{t1.t2, t2.t3}...。 在步骤4执行完成时，最终连接顺序确定为{t1.t2, t2.t3, t3.t4}。之后只需要修改LAB3中生成执行计划树的顺序即可。 测试说明 本次实验主要考察多表连接顺序的选择，测试中主要使用了 analyze 和 explain 指令。 analyze 指令用于生成直方图，计算当前数据库所有表的数值型列的统计信息，保存至 StatsManager 的 stats_map_ 中。统计信息只要求保存至内存，无需持久化到磁盘。 explain 指令用于打印查询计划树结点，本次实验主要涉及投影结点（Project Node）、连接结点（Join Node）、选择结点（Filter Node）和扫描结点（Table Scan Node）。 测试数据库中共有 4 张表： t1(id int, score float): 共 10 行 t2(id int, id2 int, score float): 共 50 行 t3(id int, score float, temp float): 共 100 行 t4(id int, id2 int, score float): 共 100 行 id 列为从 1 开始的递增序列。 id2 列为从 -1 开始的递减序列。 score 列为均匀随机值，范围 [0, 100]。 temp 列为均匀随机值，范围 [35, 38]。 score 列和 temp 列分布独立。 根据结点高度不同，打印结点前会先打印一定数量的'\\t'，高度相同的结点打印的'\\t'数量相同。 例如，对于以下 SQL 语句： explain select t2.id from t1, t2, t3 where t3.id = t1.id and t3.id = t2.id and t3.score < 30.0 and t3.temp < 36.0; 一种可能的查询计划树如下： 该计划树打印后如下所示： Select: Project Node: Join Node: Join Node: Filter Node: Table Scan Node(t3): Table Scan Node(t1): Table Scan Node(t2): 本次实验主要关注连接顺序的选择，对测试数据的每条 SQL 语句，需确保优化器选择了正确的连接顺序。对于以上示例，需确保表 t3 和 t1 先连接，其次再和表 t2 连接。 对于同一树高的左右结点顺序没有要求，因此以下几个查询计划树都可以通过测试： Select: Project Node: Join Node: Table Scan Node(t2): Join Node: Filter Node: Table Scan Node(t3): Table Scan Node(t1): Select: Project Node: Join Node: Table Scan Node(t2): Join Node: Table Scan Node(t1): Filter Node: Table Scan Node(t3): 此外，在连接顺序重排的过程中，需要确保两表之间存在连接条件，如对于 SQL explain select t2.id from t1, t2, t3, t4 where t3.score < 80.0 and t4.id = t1.id and t4.id2 = t2.id2 and t4.id = t3.id; 虽然 t1 和 t2 是基数最小的两个表，但由于 t1 和 t2 之间没有连接条件，所以不能将 t1 和 t2 优先连接。 可选高级功能 不要求将高级功能集成到主分支中，建议单开分支完成实验。但是建议同学们设计验证自己实验结果的测例并给出测试的可视化结果展示。 投影算子下推(2分:简单情况1分+复杂情况1分)：投影算子下推是一个经典的逻辑优化，通过提前执行投影算子减少算子间的数据传输量来达到优化效果。操作的主要难点在于提前解析查询树来确定需要投影的列（OperNode额外存储信息或添加额外的解析过程两种方法均可），并在执行器模型中的逐层传递中维护列ID的变化。需要设计对应的测例并对比查询计划。其中简单情况仅要求投影算子到最底层TableScan的下推过程，占1分；复杂情况需要考虑到部分中间层算子同样可以支持投影下推，例如select t.a from t where t.b < 1; 需要在TableScan后添加a,b的投影算子，并在Filter之后添加a的投影算子。复杂情况的测例需要添加至少2表JOIN，并在两个表上各添加至少一个需要下推的中间层算子，占1分。 开源数据库基数估计方法调研与实现(2分)：调研一种现有开源数据库（如 PostgreSQL，MySQL）的基数估计方法，了解现有数据库记录了直方图以外的哪些统计信息，如 PostgreSQL 的 MCV (most common values) Lists 等，以及如何利用这些统计信息实现更准确的单表基数估计。在实验框架中存储相应的统计信息，实现对应的基数估计方法，并设计测例证明方法的有效性。 高级功能满分3分。 报告说明 一门好的课程实验，都是需要多年学生的吐槽和反馈、多届助教和老师一起提升的。本次实验报告除了基本要求外，也欢迎写出对这门课的一些想法、评价和建议，如课程安排、授课方式、实验难度和工作量等，课程进行过程中有哪些好和不好的地方，未来这门课程也会根据大家的建议不断更新和改良。 截止时间 2023 年 5 月 21 日（第十三周周日）晚 23:59 分。 "},{"url":"faq.html","title":"FAQ","level":"3.1","keywords":[],"body":"常见问题 Q: 测试脚本运行 insert 正常，但在交互式命令行中复制 insert 语句运行时会卡出。 A: 部分 insert 语句较长，在交互式命令行无法工作，可以使用输入重定向方式运行，如： ./bin/cli < /path/to/00_setup.sql Q: 测试脚本运行异常且没有输出，交互式命令行中复制 SQL 运行正常。 A: 同上，尝试使用输入重定向方式运行 SQL。通常此类问题是由指针异常导致的，可以使用 gdb 等调试器进行调试。 Q: parser 解析器无法正常工作，如输入正确的 SQL 语句却显示 Syntax Error，删除 build 文件夹重新编译依然无效。 A: 可能是由于 flex 和 bison 生成的 cpp 文件出现异常，如被编辑器格式化等。可删除 parser 文件夹下的 lex.yy.cpp, sql.tab.cpp 和 sql.tab.h 文件，然后重新编译。 Q: 编译报错: ISO C++17 does not allow 'register' storage class specifier [-Wregister] A: 通常是由于使用了旧版 flex 和 bison，导致生成的代码含有 clang 编译器不支持的 register 关键词，可以通过升级 flex 和 bison 版本解决。注意：mac 系统默认会使用系统自带的 flex 和 bison，通常版本较老，可以使用 homebrew 安装，并按照安装过程中的输出信息设置相应的环境变量。 Q: 我的本地测试正常，但是 CI 无法通过测试 A: 通常是本地编译器（如clang）与评测机编译器（g++）不同导致的，可参考文档中的评测机环境，在相同的环境下编译运行代码。 "}]